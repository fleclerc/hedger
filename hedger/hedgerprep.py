# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00-hedgerprep.ipynb.

# %% auto 0
__all__ = ['directory', 'pattern', 'is_notebook', 'load_data', 'adjust_for_time', 'drop_na', 'add_spread', 'calc_bid_weight',
           'calc_ask_weight', 'add_imbalance_columns', 'add_rolling_trades_cols', 'calc_stop_loss_indices',
           'calculate_ideal_hedge', 'split_buy_sell', 'cleanup_columns', 'do_all']

# %% ../nbs/00-hedgerprep.ipynb 1
import pandas as pd
import numpy as np
import matplotlib.pyplot as plot
from fastai.tabular.all import *
import nbdev

# %% ../nbs/00-hedgerprep.ipynb 2
def is_notebook():
    try:
        shell = get_ipython().__class__.__name__
        if shell == 'ZMQInteractiveShell':
            return True   # Jupyter notebook or qtconsole
        elif shell == 'TerminalInteractiveShell':
            return False  # Terminal running IPython
        else:
            return False  # Other type (?)
    except NameError:
        return False      # Probably standard Python interpreter

# %% ../nbs/00-hedgerprep.ipynb 4
if is_notebook():
    data_dir = Path("../market")
    save_dir = Path("../market/save")
    market_open = "09:30"
    rows_to_load = 1_000_000     # should be -1 for training, or positive smaller for faster testing
    load_date = "20250103"

    day_sample_count = 5000
    print("Running in Jupyter Notebook")
else:
    data_dir = Path("../market")
    save_dir = Path("../market/save")
    market_open = "09:30"
    rows_to_load = -1     # should be -1 for training, or positive smaller for faster testing

    day_sample_count = 5000


# %% ../nbs/00-hedgerprep.ipynb 6
def load_data(date):
    if rows_to_load > 0:
        df = pd.read_csv(data_dir / f"xnas-itch-{date}.mbp-10.csv", nrows=rows_to_load)
    else:
        df = pd.read_csv(data_dir / f"xnas-itch-{date}.mbp-10.csv")
    return df

# %% ../nbs/00-hedgerprep.ipynb 9
def adjust_for_time(df):
    df["ts_event"] = pd.to_datetime(df.ts_event, unit="ns")
    df["ts_event"] = df["ts_event"].dt.tz_convert('US/Eastern')
    df = df[df["ts_event"].dt.time >= pd.to_datetime("09:30").time()]
    df = df[df["ts_event"].dt.time <= pd.to_datetime("16:00").time()]
    #df.set_index('ts_event', inplace=True)

    market_open = pd.to_datetime("09:30").time()
    print(market_open)
    df['ns_since_open'] = (df['ts_event'] - df['ts_event'].dt.normalize() - pd.to_timedelta(market_open.hour, unit='h') - pd.to_timedelta(market_open.minute, unit='m')).dt.total_seconds() * 1e9 + df['ts_event'].dt.nanosecond

    df = add_datepart(df, 'ts_event', drop=False)
    return df

# %% ../nbs/00-hedgerprep.ipynb 12
def drop_na(df):
    orig_len = df.shape[0]
    df.dropna(inplace=True)
    cur_len = df.shape[0]
    drop_cnt = orig_len-cur_len
    if  drop_cnt > 1000:
        raise Exception(f"{drop_cnt} rows dropped, seems a lot")
    else:
        print(f"{drop_cnt} dropped out of {orig_len}")

# %% ../nbs/00-hedgerprep.ipynb 19
def add_spread(df):
    df['spread'] = (df['ask_px_00'] - df['bid_px_00'])/((df['bid_px_00']+df['ask_px_00'])/2)

# %% ../nbs/00-hedgerprep.ipynb 22
def calc_bid_weight(row):
    return  np.array([row['mid']/(row['mid']-row[f'bid_px_0{i}'])*row[f'bid_sz_0{i}'] for i in range(0,10)]).sum(axis=0)
def calc_ask_weight(row): 
    return np.array([row['mid']/(row[f'ask_px_0{i}']-row['mid'])*row[f'ask_sz_0{i}'] for i in range(0,10)]).sum(axis=0)    

def add_imbalance_columns(df):
    # want to calculate the amount but also how spread out it is
    df['mid'] = (df['bid_px_00']+df['ask_px_00'])/2
    df['bid_weight'] = calc_bid_weight(df)
    df['ask_weight'] = calc_ask_weight(df)
    df['bid_weight_log'] = np.log(df['bid_weight'])
    df['ask_weight_log'] = np.log(df['ask_weight'])


# %% ../nbs/00-hedgerprep.ipynb 26
def add_rolling_trades_cols(df):
    # add a column with a the traded size by row, with 0 for non trade rows
    # this makes the next calculation easier
    df["traded_bid_size"] = df["size"] * ((df["action"] == "T") & (df["side"] == "B"))
    df["traded_ask_size"] = df["size"] * ((df["action"] == "T") & (df["side"] == "A"))
    df["is_trade_bid"] = ((df["action"] == "T") & (df["side"] == "B")) * 1
    df["is_trade_ask"] = ((df["action"] == "T") & (df["side"] == "A")) * 1

    def add_rolling_trades_cols(period):
        # temporary dataset so we can reindex
        x = df[['ts_event', 'traded_bid_size', 'traded_ask_size', 'is_trade_bid', 'is_trade_ask']].copy()
        x['original_index'] = df.index
        x.set_index("ts_event", inplace=True)

        # calculate
        x[f'rolling_{period}_bid_size'] = x["traded_bid_size"].rolling(period).sum()
        x[f'rolling_{period}_ask_size'] = x["traded_ask_size"].rolling(period).sum()
        x[f'rolling_{period}_bid_cnt'] = x["is_trade_bid"].rolling(period).sum()
        x[f'rolling_{period}_ask_cnt'] = x["is_trade_ask"].rolling(period).sum()

        # merge back to original dataframe
        x.set_index("original_index", inplace=True)
        df[f'rolling_{period}_bid_size'] = x[f'rolling_{period}_bid_size']
        df[f'rolling_{period}_ask_size'] = x[f'rolling_{period}_ask_size']
        df[f'rolling_{period}_bid_cnt'] = x[f'rolling_{period}_bid_cnt']
        df[f'rolling_{period}_ask_cnt'] = x[f'rolling_{period}_ask_cnt']


    add_rolling_trades_cols('30s')
    add_rolling_trades_cols('5min')

    # and cleanup
    _ = df.drop(columns=['traded_bid_size', 'traded_ask_size', 'is_trade_bid', 'is_trade_ask'])



# %% ../nbs/00-hedgerprep.ipynb 30
def calc_stop_loss_indices(df):
    rdf = df[df['action'] == 'A'].sample(n=day_sample_count)
    #rdf['hedge_buy_exec_idx'] = rdf.apply(lambda row: df.index[(df.index > row.name) & (df['ask_px_00'] <= row['bid_px_00'])].min(), axis=1)
    #rdf['hedge_sell_exec_idx'] = rdf.apply(lambda row: df.index[(df.index > row.name) & (df['bid_px_00'] >= row['ask_px_00'])].min(), axis=1)

    rdf['hedge_buy_stop_idx'] = rdf.apply(lambda row: df.index[(df.index > row.name) & (df['bid_px_00'] >= row['bid_px_00']+0.02)].min(), axis=1)
    rdf['hedge_sell_stop_idx'] = rdf.apply(lambda row: df.index[(df.index > row.name) & (df['ask_px_00'] <= row['ask_px_00']-0.02)].min(), axis=1)
    return rdf


# %% ../nbs/00-hedgerprep.ipynb 32
def calculate_ideal_hedge(df, rdf):
    # fix NaN values
    rdf['hedge_buy_stop_idx'] = rdf['hedge_buy_stop_idx'].where(~rdf['hedge_buy_stop_idx'].isna(), rdf.index)
    rdf['hedge_sell_stop_idx'] = rdf['hedge_sell_stop_idx'].where(~rdf['hedge_sell_stop_idx'].isna(), rdf.index)

    # convert idexes to int
    rdf['hedge_buy_stop_idx'] = rdf['hedge_buy_stop_idx'].astype(int)
    rdf['hedge_sell_stop_idx'] = rdf['hedge_sell_stop_idx'].astype(int)


    def optimal_buy_price(row):
        idx = df.index.get_loc(row.name)
        return df.iloc[idx:idx+1+row['hedge_buy_stop_idx']]['ask_px_00'].min()

    def optimal_sell_price(row):
        idx = df.index.get_loc(row.name)
        return df.iloc[idx:idx+1+row['hedge_sell_stop_idx']]['bid_px_00'].max()

    # calculate ideal position between current point and stop loss point 
    rdf['ideal_buy_price'] = rdf.apply(optimal_buy_price, axis=1)
    rdf['ideal_sell_price'] = rdf.apply(optimal_sell_price, axis=1)

    rdf['ideal_buy_price_spread'] = (rdf['ideal_buy_price'] - rdf['bid_px_00']) / (rdf['ask_px_00'] - rdf['bid_px_00'])
    rdf['ideal_sell_price_spread'] = (rdf['ideal_sell_price'] - rdf['ask_px_00']) / (rdf['ask_px_00'] - rdf['bid_px_00'])

# %% ../nbs/00-hedgerprep.ipynb 38
def split_buy_sell(df):
    rdf_buy = df.copy()
    rdf_buy['is_buy'] = True
    rdf_buy['ideal_price'] = rdf_buy['ideal_buy_price']
    rdf_buy['ideal_price_spread'] = rdf_buy['ideal_buy_price_spread']
    rdf_buy.drop(columns=['ideal_buy_price'], inplace=True)

    rdf_sell = df.copy()
    rdf_sell['is_buy'] = False
    rdf_sell['ideal_price'] = rdf_sell['ideal_sell_price']
    rdf_sell['ideal_price_spread'] = rdf_buy['ideal_sell_price_spread']
    rdf_sell.drop(columns=['ideal_sell_price'], inplace=True)

    rdf_combined = pd.concat([rdf_buy, rdf_sell])
    return rdf_combined


# %% ../nbs/00-hedgerprep.ipynb 41
def cleanup_columns(df):
    for i in range(0, 10):
        df.drop(columns=[f'bid_px_0{i}', f'ask_px_0{i}'], inplace=True)
        df.drop(columns=[f'bid_sz_0{i}', f'ask_sz_0{i}'], inplace=True)
        df.drop(columns=[f'bid_ct_0{i}', f'ask_ct_0{i}'], inplace=True)

# %% ../nbs/00-hedgerprep.ipynb 45
from pathlib import Path

def do_all(date):
    df = load_data(date)
    df = adjust_for_time(df)
    drop_na(df)
    add_spread(df)
    add_imbalance_columns(df)
    rdf = calc_stop_loss_indices(df)
    calculate_ideal_hedge(df, rdf)
    rdf_combined = split_buy_sell(rdf)
    cleanup_columns(rdf_combined)
    rdf_combined.to_csv(save_dir / f'rdf_output_{date}.csv', index=False)


# Define the directory and pattern
directory = Path("../market")
pattern = "*mbp-10*"
print("here")
# Iterate over files matching the pattern
for file_path in directory.glob(pattern):
    print(file_path)

    # Extract the date from the file name
    date_str = file_path.name[10:18]
    print(f"Extracted date: {date_str}")
    do_all(date_str)
