# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00-hedgerprep.ipynb.

# %% auto 0
__all__ = ['stop_loss_tick', 'tick_size', 'is_notebook', 'load_data', 'adjust_for_time', 'drop_na', 'add_spread',
           'calc_bid_weight', 'calc_ask_weight', 'add_imbalance_columns', 'add_rolling_trades_cols',
           'calc_stop_loss_indices', 'calculate_ideal_hedge', 'split_buy_sell', 'cleanup_columns']

# %% ../nbs/00-hedgerprep.ipynb 2
import pandas as pd
import numpy as np
import matplotlib.pyplot as plot
from fastai.tabular.all import *
import nbdev
import gzip

# %% ../nbs/00-hedgerprep.ipynb 3
def is_notebook():
    try:
        shell = get_ipython().__class__.__name__
        if shell == 'ZMQInteractiveShell':
            return True   # Jupyter notebook or qtconsole
        elif shell == 'TerminalInteractiveShell':
            return False  # Terminal running IPython
        else:
            return False  # Other type (?)
    except NameError:
        return False      # Probably standard Python interpreter

# %% ../nbs/00-hedgerprep.ipynb 5
stop_loss_tick = 2
tick_size = 0.01

if is_notebook():
    data_dir = Path("../market")
    save_dir = Path("../market/save")
    market_open = "09:30"
    rows_to_load = 3_000_000     # should be -1 for training, or positive smaller for faster testing
    load_date = "20250103"

    day_sample_count = 5000
    print("Running in Jupyter Notebook")
else:
    data_dir = Path("../market")
    save_dir = Path("../market/save")
    market_open = "09:30"
    rows_to_load = -1     # should be -1 for training, or positive smaller for faster testing

    day_sample_count = 5000


# %% ../nbs/00-hedgerprep.ipynb 7
def load_data(date):
    file_path = data_dir / f"xnas-itch-{date}.mbp-10.csv"
    if not file_path.exists():
        file_path = data_dir / f"xnas-itch-{date}.mbp-10.csv.gz"
        if file_path.exists():
            with gzip.open(file_path, 'rb') as f:
                decompressed_data = f.read()
            df = pd.read_csv(io.BytesIO(decompressed_data), nrows=rows_to_load if rows_to_load > 0 else None)
        else:
            raise FileNotFoundError(f"Neither {file_path} nor its .gz version exists.")
    else:
        df = pd.read_csv(file_path, nrows=rows_to_load if rows_to_load > 0 else None)
    return df

# %% ../nbs/00-hedgerprep.ipynb 10
def adjust_for_time(df):
    df["ts_event"] = pd.to_datetime(df.ts_event, unit="ns")
    df["ts_event"] = df["ts_event"].dt.tz_convert('US/Eastern')
    df = df[df["ts_event"].dt.time >= pd.to_datetime("09:30").time()]
    df = df[df["ts_event"].dt.time <= pd.to_datetime("16:00").time()]
    #df.set_index('ts_event', inplace=True)

    market_open = pd.to_datetime("09:30").time()
    print(market_open)
    df['ns_since_open'] = (df['ts_event'] - df['ts_event'].dt.normalize() - pd.to_timedelta(market_open.hour, unit='h') - pd.to_timedelta(market_open.minute, unit='m')).dt.total_seconds() * 1e9 + df['ts_event'].dt.nanosecond

    df = add_datepart(df, 'ts_event', drop=False)
    return df

# %% ../nbs/00-hedgerprep.ipynb 13
def drop_na(df):
    orig_len = df.shape[0]
    df.dropna(inplace=True)
    cur_len = df.shape[0]
    drop_cnt = orig_len-cur_len
    if  drop_cnt > 1000:
        raise Exception(f"{drop_cnt} rows dropped, seems a lot")
    else:
        print(f"{drop_cnt} dropped out of {orig_len}")

# %% ../nbs/00-hedgerprep.ipynb 20
def add_spread(df):
    df['spread'] = (df['ask_px_00'] - df['bid_px_00'])/((df['bid_px_00']+df['ask_px_00'])/2)

# %% ../nbs/00-hedgerprep.ipynb 23
def calc_bid_weight(row):
    return  np.array([row['mid']/(row['mid']-row[f'bid_px_0{i}'])*row[f'bid_sz_0{i}'] for i in range(0,10)]).sum(axis=0)
def calc_ask_weight(row): 
    return np.array([row['mid']/(row[f'ask_px_0{i}']-row['mid'])*row[f'ask_sz_0{i}'] for i in range(0,10)]).sum(axis=0)    

def add_imbalance_columns(df):
    # want to calculate the amount but also how spread out it is
    df['mid'] = (df['bid_px_00']+df['ask_px_00'])/2
    df['bid_weight'] = calc_bid_weight(df)
    df['ask_weight'] = calc_ask_weight(df)
    df['bid_weight_log'] = np.log(df['bid_weight'])
    df['ask_weight_log'] = np.log(df['ask_weight'])


# %% ../nbs/00-hedgerprep.ipynb 27
def add_rolling_trades_cols(df):
    # add a column with a the traded size by row, with 0 for non trade rows
    # this makes the next calculation easier
    df["traded_bid_size"] = df["size"] * ((df["action"] == "T") & (df["side"] == "B"))
    df["traded_ask_size"] = df["size"] * ((df["action"] == "T") & (df["side"] == "A"))
    df["is_trade_bid"] = ((df["action"] == "T") & (df["side"] == "B")) * 1
    df["is_trade_ask"] = ((df["action"] == "T") & (df["side"] == "A")) * 1

    def add_rolling_trades_cols(period):
        # temporary dataset so we can reindex
        x = df[['ts_event', 'traded_bid_size', 'traded_ask_size', 'is_trade_bid', 'is_trade_ask']].copy()
        x['original_index'] = df.index
        x.set_index("ts_event", inplace=True)

        # calculate
        x[f'rolling_{period}_bid_size'] = x["traded_bid_size"].rolling(period).sum()
        x[f'rolling_{period}_ask_size'] = x["traded_ask_size"].rolling(period).sum()
        x[f'rolling_{period}_bid_cnt'] = x["is_trade_bid"].rolling(period).sum()
        x[f'rolling_{period}_ask_cnt'] = x["is_trade_ask"].rolling(period).sum()

        # merge back to original dataframe
        x.set_index("original_index", inplace=True)
        df[f'rolling_{period}_bid_size'] = x[f'rolling_{period}_bid_size']
        df[f'rolling_{period}_ask_size'] = x[f'rolling_{period}_ask_size']
        df[f'rolling_{period}_bid_cnt'] = x[f'rolling_{period}_bid_cnt']
        df[f'rolling_{period}_ask_cnt'] = x[f'rolling_{period}_ask_cnt']


    add_rolling_trades_cols('30s')
    add_rolling_trades_cols('5min')

    # and cleanup
    _ = df.drop(columns=['traded_bid_size', 'traded_ask_size', 'is_trade_bid', 'is_trade_ask'])



# %% ../nbs/00-hedgerprep.ipynb 31
def calc_stop_loss_indices(df):
    # reduce dataset
    rdf = df[df['action'] == 'A'].sample(n=day_sample_count)
    
    stop_loss_currency = stop_loss_tick * tick_size - (tick_size / 10.0)  # substract 1/10 tick otherwise I get issues with floating point approximations
    
    rdf['hedge_buy_stop_idx'] = rdf.apply(lambda row: df.index[(df.index > row.name) & (df['ask_px_00'] >= row['ask_px_00']+ stop_loss_currency )].min(), axis=1)
    rdf['hedge_sell_stop_idx'] = rdf.apply(lambda row: df.index[(df.index > row.name) & (df['bid_px_00'] <= row['bid_px_00']- stop_loss_currency)].min(), axis=1)
    # add columns with the stop loss prices, will come handy when we introduce latency

    rdf['hedge_buy_stop_prc'] = rdf.loc[rdf['hedge_buy_stop_idx'].notnull()]['ask_px_00']
    rdf['hedge_sell_stop_prc'] = rdf.loc[rdf['hedge_sell_stop_idx'].notnull()]['bid_px_00']

    # convert idexes to int

    rdf['hedge_buy_stop_idx'] = rdf['hedge_buy_stop_idx'].astype('int', errors='ignore')
    rdf['hedge_sell_stop_idx'] = rdf['hedge_sell_stop_idx'].astype('int', errors='ignore')
    return rdf


# %% ../nbs/00-hedgerprep.ipynb 37
def calculate_ideal_hedge(df, rdf):
    # fix NaN values
    rdf['hedge_buy_stop_idx'] = rdf['hedge_buy_stop_idx'].where(~rdf['hedge_buy_stop_idx'].isna(), rdf.index)
    rdf['hedge_sell_stop_idx'] = rdf['hedge_sell_stop_idx'].where(~rdf['hedge_sell_stop_idx'].isna(), rdf.index)

    rdf['hedge_buy_stop_prc'] = rdf['hedge_buy_stop_prc'].where(~rdf['hedge_buy_stop_prc'].isna(), rdf['ask_px_00'])
    rdf['hedge_sell_stop_prc'] = rdf['hedge_sell_stop_prc'].where(~rdf['hedge_sell_stop_prc'].isna(), rdf['bid_px_00'])

    def optimal_buy_price(row):
        idx = df.index.get_loc(row.name)
        return df.iloc[idx:idx+1+row['hedge_buy_stop_idx']]['ask_px_00'].min()

    def optimal_sell_price(row):
        idx = df.index.get_loc(row.name)
        return df.iloc[idx:idx+1+row['hedge_sell_stop_idx']]['bid_px_00'].max()

    # calculate ideal position between current point and stop loss point 
    rdf['ideal_buy_price'] = rdf.apply(optimal_buy_price, axis=1)
    rdf['ideal_sell_price'] = rdf.apply(optimal_sell_price, axis=1)

    rdf['ideal_buy_price_spread'] = (rdf['ideal_buy_price'] - rdf['bid_px_00']) / (rdf['ask_px_00'] - rdf['bid_px_00'])
    rdf['ideal_sell_price_spread'] = -(rdf['ideal_sell_price'] - rdf['ask_px_00']) / (rdf['ask_px_00'] - rdf['bid_px_00'])

# %% ../nbs/00-hedgerprep.ipynb 42
def split_buy_sell(df):
    def split_side(side):
        rdf_side = df.copy()
        rdf_side['is_buy'] = True
        rdf_side['ideal_price'] = rdf_side[f'ideal_{side}_price']
        rdf_side['ideal_price_spread'] = rdf_side[f'ideal_{side}_price_spread']
        rdf_side['hedge_stop_prc'] = rdf_side[f'hedge_{side}_stop_prc']
        rdf_side.drop(columns=[f'ideal_{side}_price'], inplace=True)
        return rdf_side

    rdf_buy = split_side('buy')
    rdf_sell = split_side('sell')

    rdf_combined = pd.concat([rdf_buy, rdf_sell])
    return rdf_combined


# %% ../nbs/00-hedgerprep.ipynb 46
def cleanup_columns(df):
    for i in range(1, 10):
        df.drop(columns=[f'bid_px_0{i}', f'ask_px_0{i}'], inplace=True)
    for i in range(0, 10):
        df.drop(columns=[f'bid_sz_0{i}', f'ask_sz_0{i}'], inplace=True)
        df.drop(columns=[f'bid_ct_0{i}', f'ask_ct_0{i}'], inplace=True)

# %% ../nbs/00-hedgerprep.ipynb 50
if not is_notebook():
    from pathlib import Path
    import time

    def do_all(date):
        start_time = time.time()
        print("Step 1: Loading data")
        df = load_data(date)
        print(f"Step 2: Adjusting for time (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        df = adjust_for_time(df)
        print(f"Step 3: Dropping NA (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        drop_na(df)
        print(f"Step 4: Adding spread (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        add_spread(df)
        print(f"Step 5: Adding imbalance columns (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        add_imbalance_columns(df)
        print(f"Step 6: Calculating stop loss indices (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        rdf = calc_stop_loss_indices(df)
        print(f"Step 7: Calculating ideal hedge (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        calculate_ideal_hedge(df, rdf)
        print(f"Step 8: Splitting buy and sell (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        rdf_combined = split_buy_sell(rdf)
        print(f"Step 9: Cleaning up columns (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        cleanup_columns(rdf_combined)
        print(f"Step 10: Saving to CSV (took {time.time() - start_time:.2f} seconds)")
        start_time = time.time()
        rdf_combined.to_csv(save_dir / f'rdf_output_{date}.csv', index=False)

    # Define the directory and pattern
    directory = Path("../market")
    pattern = "*mbp-10*"
    print("here")
    # Iterate over files matching the pattern
    for file_path in directory.glob(pattern):
        print(file_path)
        # Extract the date from the filename
        date_str = file_path.name[10:18]
        print(f"Extracted date: {date_str}")
        do_all(date_str)
